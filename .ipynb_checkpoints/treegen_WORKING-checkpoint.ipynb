{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import log2\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "# class Node:\n",
    "#     def __init__(self, emitter=None, split=None, roomlabel=None):\n",
    "#         self.right = None\n",
    "#         self.left = None\n",
    "#         self.emitter = emitter\n",
    "#         self.split = split\n",
    "#         self.roomlabel = roomlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(roomData):\n",
    "    H=0.0\n",
    "    i=0\n",
    "    scoreboard = {1:0, 2:0, 3:0, 4:0}\n",
    "    size = len(roomData)\n",
    "    while i<size:\n",
    "        if roomData[i][-1] == 1:\n",
    "            scoreboard[1]+=1\n",
    "        elif roomData[i][-1] == 2:\n",
    "            scoreboard[2]+=1\n",
    "        elif roomData[i][-1] == 3:\n",
    "            scoreboard[3]+=1\n",
    "        elif roomData[i][-1] == 4:\n",
    "            scoreboard[4]+=1\n",
    "        i+=1;\n",
    "    for i in (1,2,3,4):\n",
    "        if scoreboard[i] > 0:\n",
    "            H += ((-scoreboard[i])/size)*(log2(scoreboard[i]/size))\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InfoGain(All, Left, Right):\n",
    "    H_SAll=entropy(All)\n",
    "    Total=len(Left)+len(Right)\n",
    "    Remainder=((len(Left)/Total)*entropy(Left))+((len(Right)/Total)*entropy(Right))\n",
    "    Gains=H_SAll-Remainder\n",
    "    return Gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FIND_SPLIT(d):\n",
    "    emitter = 0\n",
    "    value = 0\n",
    "    max_info_gain = 0\n",
    "    for x in range(len(d[0])-1):\n",
    "        #d.sort(d,key = lambda y: y[x])\n",
    "        ds = np.array(sorted(d, key = lambda y: y[x], reverse=True))\n",
    "        #print(ds)\n",
    "        for r in range(len(ds)):\n",
    "            \n",
    "            split_point = ds[r][x]\n",
    "            if(r!=len(ds)-1 and ds[r+1][x] == split_point):\n",
    "                continue\n",
    "            info_gain = InfoGain(ds, ds[:r+1],ds[r+1:])\n",
    "            \n",
    "            if(info_gain > max_info_gain):\n",
    "                emitter = x\n",
    "                value = split_point\n",
    "                max_info_gain = info_gain\n",
    "            \n",
    "            \n",
    "        \n",
    "    return emitter, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(clean_rows):\n",
    "    Left = []\n",
    "    Right = []\n",
    "    em, val = FIND_SPLIT(clean_rows) #splitvalue[0] = emitter and splitvalue[1] = value under that column\n",
    "    \n",
    "    for i in range(len(clean_rows)):\n",
    "        if(clean_rows[i][em] >= val):\n",
    "            Left.append(clean_rows[i])\n",
    "        \n",
    "        else:\n",
    "            Right.append(clean_rows[i])\n",
    "        \n",
    "    \n",
    "    \n",
    "    return np.array(Left),np.array(Right),em,val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_learning(training_data, depth):\n",
    "    if(entropy(training_data) == 0 and len(training_data) != 0):\n",
    "        label = training_data[0][-1]\n",
    "        leaf = {'emitter':None, 'value':None, 'room': label, 'right':None, 'left':None}\n",
    "        return leaf, depth\n",
    "    else:\n",
    "        ldata, rdata, em, val = split(training_data)\n",
    "        root = {'emitter': em, 'value': val, 'room': None, 'right':None, 'left':None}\n",
    "        root['left'], l_depth = tree_learning(ldata, depth+1)\n",
    "        root['right'], r_depth = tree_learning(rdata, depth+1)\n",
    "        return root, max(l_depth, r_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tree_learning2(training_data):\n",
    "#     if(entropy(training_data) == 0):\n",
    "#         label = training_data[0][-1]\n",
    "#         leaf = Node(roomlabel=label)\n",
    "#         return leaf\n",
    "#     else:\n",
    "#         ldata, rdata, em, val = split(training_data)\n",
    "#         root = Node(emitter=em, split=val)\n",
    "#         root.left = tree_learning2(ldata)\n",
    "#         root.right = tree_learning2(rdata)\n",
    "#         return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-64. -56. -61. ... -82. -81.   1.]\n",
      " [-68. -57. -61. ... -85. -85.   1.]\n",
      " [-63. -60. -60. ... -85. -84.   1.]\n",
      " ...\n",
      " [-62. -59. -46. ... -87. -88.   4.]\n",
      " [-62. -58. -52. ... -90. -85.   4.]\n",
      " [-59. -50. -45. ... -88. -87.   4.]]\n"
     ]
    }
   ],
   "source": [
    "clean_rows = np.loadtxt(\"clean_dataset.txt\")\n",
    "noisy_rows = np.loadtxt(\"noisy_dataset.txt\")\n",
    "print(clean_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, d = tree_learning(noisy_rows, 0)\n",
    "#print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(dataset):\n",
    "\n",
    "#shuffle \n",
    "    np.random.shuffle(dataset)\n",
    "#take a set\n",
    "    fold_size = int(len(dataset)/10)\n",
    "    test = dataset[0:fold_size]\n",
    "    classes = set({})\n",
    "    confusion_matrix_array = []\n",
    "    \n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        classes.add(dataset[i][-1])\n",
    "    \n",
    "    for i in range(10):\n",
    "        test = dataset[0+fold_size*i:fold_size*(i+1)]\n",
    "        training = np.vstack((dataset[0:0+fold_size*i],dataset[fold_size*(i+1):]))\n",
    "        root, depth = tree_learning(training, 0)\n",
    "        #accuracy, confusion_matrix = evaluate(test, root)\n",
    "        confusion_matrix = evaluate(test, root)\n",
    "        confusion_matrix_array.append(confusion_matrix)\n",
    "        print(accuracy(confusion_matrix))\n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "#cycle validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test, root): #why we do like this we dont need to\n",
    "    #recurse on evaluate we can make a function to just return the leaf value and comapre in the for loop and form\n",
    "    #the whole matrix here, the other function will just return our value\n",
    "    \n",
    "    arr = []\n",
    "    \n",
    "    for row in test:\n",
    "        prediction = return_result(row, root)\n",
    "        arr.append([row[-1],prediction])\n",
    "        \n",
    "    #print(arr)\n",
    "    return confuse_matrix(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confuse_matrix(arr): \n",
    "    \n",
    "    cm = np.zeros((4,4))\n",
    "    \n",
    "    for i in range (1,5):\n",
    "        for pair in arr:\n",
    "            if(i == pair[0] and pair[0] == pair[1]):\n",
    "                    cm[i-1][i-1]+=1\n",
    "            if(i == pair[0] and pair[1] != i):\n",
    "                    cm[i-1][int(pair[1])-1]+=1\n",
    "    return cm\n",
    "    \n",
    "#confuse_matrix([[1, 1], [2, 2], [3,3], [1,2], [1,3], [3,1], [4,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_result(row, root):\n",
    "    \n",
    "    if(root['room']!= None):\n",
    "        return root['room']\n",
    "    else:\n",
    "        if(row[root['emitter']]>=root['value']):\n",
    "            return return_result(row, root['left'])\n",
    "        else:\n",
    "            return return_result(row, root['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(cm):\n",
    "    return np.trace(cm)/np.sum(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82\n",
      "0.83\n",
      "0.85\n",
      "0.765\n",
      "0.795\n",
      "0.72\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "testing = np.loadtxt(\"clean_dataset.txt\")\n",
    "st=time.time()\n",
    "cross_validation(testing)\n",
    "et=time.time()\n",
    "print('Runtime: ', et-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
