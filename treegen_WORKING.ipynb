{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from math import log2\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "# class Node:\n",
    "#     def __init__(self, emitter=None, split=None, roomlabel=None):\n",
    "#         self.right = None\n",
    "#         self.left = None\n",
    "#         self.emitter = emitter\n",
    "#         self.split = split\n",
    "#         self.roomlabel = roomlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(roomData):\n",
    "    H=0.0\n",
    "    i=0\n",
    "    scoreboard = {1:0, 2:0, 3:0, 4:0}\n",
    "    size = len(roomData)\n",
    "    while i<size:\n",
    "        if roomData[i][-1] == 1:\n",
    "            scoreboard[1]+=1\n",
    "        elif roomData[i][-1] == 2:\n",
    "            scoreboard[2]+=1\n",
    "        elif roomData[i][-1] == 3:\n",
    "            scoreboard[3]+=1\n",
    "        elif roomData[i][-1] == 4:\n",
    "            scoreboard[4]+=1\n",
    "        i+=1;\n",
    "    for i in (1,2,3,4):\n",
    "        if scoreboard[i] > 0:\n",
    "            H += ((-scoreboard[i])/size)*(log2(scoreboard[i]/size))\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InfoGain(All, Left, Right):\n",
    "    H_SAll=entropy(All)\n",
    "    Total=len(Left)+len(Right)\n",
    "    Remainder=((len(Left)/Total)*entropy(Left))+((len(Right)/Total)*entropy(Right))\n",
    "    Gains=H_SAll-Remainder\n",
    "    return Gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FIND_SPLIT(d):\n",
    "    emitter = 0\n",
    "    value = 0\n",
    "    max_info_gain = 0\n",
    "    for x in range(len(d[0])-1):\n",
    "        #d.sort(d,key = lambda y: y[x])\n",
    "        ds = np.array(sorted(d, key = lambda y: y[x], reverse=True))\n",
    "        #print(ds)\n",
    "        for r in range(len(ds)):\n",
    "            \n",
    "            split_point = ds[r][x]\n",
    "            if(r!=len(ds)-1 and ds[r+1][x] == split_point):\n",
    "                continue\n",
    "            info_gain = InfoGain(ds, ds[:r+1],ds[r+1:])\n",
    "            \n",
    "            if(info_gain > max_info_gain):\n",
    "                emitter = x\n",
    "                value = split_point\n",
    "                max_info_gain = info_gain\n",
    "            \n",
    "            \n",
    "        \n",
    "    return emitter, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(clean_rows):\n",
    "    Left = []\n",
    "    Right = []\n",
    "    em, val = FIND_SPLIT(clean_rows) #splitvalue[0] = emitter and splitvalue[1] = value under that column\n",
    "    \n",
    "    for i in range(len(clean_rows)):\n",
    "        if(clean_rows[i][em] >= val):\n",
    "            Left.append(clean_rows[i])\n",
    "        \n",
    "        else:\n",
    "            Right.append(clean_rows[i])\n",
    "        \n",
    "    \n",
    "    \n",
    "    return np.array(Left),np.array(Right),em,val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_learning(training_data, depth):\n",
    "    if(entropy(training_data) == 0 and len(training_data) != 0):\n",
    "        count = len(training_data)\n",
    "        label = training_data[0][-1]\n",
    "        leaf = {'emitter':-1, 'value':-1, 'room': label, 'right':-1, 'left':-1, 'count': count}\n",
    "        return leaf, depth\n",
    "    else:\n",
    "        ldata, rdata, em, val = split(training_data)\n",
    "        root = {'emitter': em, 'value': val, 'room': -1, 'right':-1, 'left':-1, 'count': -1}\n",
    "        root['left'], l_depth = tree_learning(ldata, depth+1)\n",
    "        root['right'], r_depth = tree_learning(rdata, depth+1)\n",
    "        return root, max(l_depth, r_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tree_learning2(training_data):\n",
    "#     if(entropy(training_data) == 0):\n",
    "#         label = training_data[0][-1]\n",
    "#         leaf = Node(roomlabel=label)\n",
    "#         return leaf\n",
    "#     else:\n",
    "#         ldata, rdata, em, val = split(training_data)\n",
    "#         root = Node(emitter=em, split=val)\n",
    "#         root.left = tree_learning2(ldata)\n",
    "#         root.right = tree_learning2(rdata)\n",
    "#         return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-64. -56. -61. ... -82. -81.   1.]\n",
      " [-68. -57. -61. ... -85. -85.   1.]\n",
      " [-63. -60. -60. ... -85. -84.   1.]\n",
      " ...\n",
      " [-62. -59. -46. ... -87. -88.   4.]\n",
      " [-62. -58. -52. ... -90. -85.   4.]\n",
      " [-59. -50. -45. ... -88. -87.   4.]]\n"
     ]
    }
   ],
   "source": [
    "clean_rows = np.loadtxt(\"clean_dataset.txt\")\n",
    "noisy_rows = np.loadtxt(\"noisy_dataset.txt\")\n",
    "print(clean_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, d = tree_learning(noisy_rows, 0)\n",
    "#print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(dataset):\n",
    "\n",
    "#shuffle \n",
    "    np.random.shuffle(dataset)\n",
    "#take a set\n",
    "    fold_size = int(len(dataset)/10)\n",
    "    test = dataset[0:fold_size]\n",
    "    validation = []\n",
    "    classes = set({})\n",
    "    running_cm = np.zeros((4,4))\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        classes.add(dataset[i][-1])\n",
    "    \n",
    "    for i in range(10):\n",
    "        test = dataset[0+fold_size*i:fold_size*(i+1)]\n",
    "        training = np.vstack((dataset[0:0+fold_size*i],dataset[fold_size*(i+1):]))\n",
    "        root, depth = tree_learning(training, 0)\n",
    "        \n",
    "        confusion_matrix, tree_accuracy = evaluate(test, root)        \n",
    "        running_cm += confusion_matrix\n",
    "        \n",
    "        #pruned_tree = prune(root, validation set)\n",
    "        \n",
    "        \n",
    "    \n",
    "    avg_cm = running_cm/10\n",
    "    \n",
    "    return accuracy(avg_cm)\n",
    "    \n",
    "    \n",
    "        \n",
    "#cycle validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test, root): #why we do like this we dont need to\n",
    "    #recurse on evaluate we can make a function to just return the leaf value and comapre in the for loop and form\n",
    "    #the whole matrix here, the other function will just return our value\n",
    "    \n",
    "    arr = []\n",
    "    \n",
    "    for row in test:\n",
    "        prediction = return_result(row, root)\n",
    "        arr.append([row[-1],prediction])\n",
    "        \n",
    "    #print(arr)\n",
    "    cm = confuse_matrix(arr)\n",
    "    tree_accuracy = accuracy(cm)\n",
    "    \n",
    "    return cm, tree_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confuse_matrix(arr): \n",
    "    \n",
    "    cm = np.zeros((4,4))\n",
    "    \n",
    "    for i in range (1,5):\n",
    "        for pair in arr:\n",
    "            if(i == pair[0] and pair[0] == pair[1]):\n",
    "                    cm[i-1][i-1]+=1\n",
    "            if(i == pair[0] and pair[1] != i):\n",
    "                    cm[i-1][int(pair[1])-1]+=1\n",
    "    return cm\n",
    "    \n",
    "#confuse_matrix([[1, 1], [2, 2], [3,3], [1,2], [1,3], [3,1], [4,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_result(row, root):\n",
    "    \n",
    "    if(root['room']!= -1):\n",
    "        return root['room']\n",
    "    else:\n",
    "        if(row[root['emitter']]>=root['value']):\n",
    "            return return_result(row, root['left'])\n",
    "        else:\n",
    "            return return_result(row, root['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(cm):\n",
    "#     sum = 0\n",
    "#     trace = 0\n",
    "#     for i in range(len(cm)):\n",
    "#         trace+=cm[i][i]\n",
    "#     for i in cm:\n",
    "#         sum+=i.sum()\n",
    "    if(np.sum(cm) == 0):\n",
    "        return 0\n",
    "    return np.trace(cm)/np.sum(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.973\n",
      "Runtime:  71.2025740146637\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------#\n",
    "testing = np.loadtxt(\"clean_dataset.txt\")\n",
    "st=time.time()\n",
    "print(cross_validation(testing))\n",
    "et=time.time()\n",
    "print('Runtime: ', et-st)\n",
    "#-----------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(cm):\n",
    "    arr = []\n",
    "    cols = cm.sum(axis=0)\n",
    "    \n",
    "    for i in range(len(cm)):\n",
    "        arr.append(cm[i][i]/cols[i])\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(cm):\n",
    "    arr = []\n",
    "    rows = cm.sum(axis=1)\n",
    "   \n",
    "    for i in range(len(cm)):\n",
    "        arr.append(cm[i][i]/rows[i])\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 0.23076923076923078, 0.2619047619047619, 0.27586206896551724]\n",
      "[0.03571428571428571, 0.1875, 0.3055555555555556, 0.4]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,17).reshape(4,4)\n",
    "#print(a)\n",
    "print(recall(a))\n",
    "print(precision(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(recall, precision):\n",
    "    arr = []\n",
    "    for i in range(len(recall)):\n",
    "        arr.append(2*r[i]*p[i]/r[i]+p[i])\n",
    "    \n",
    "    return arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10714285714285714, 0.5625, 0.9166666666666667, 1.2000000000000002]\n"
     ]
    }
   ],
   "source": [
    "r = [0.1, 0.23076923076923078, 0.2619047619047619, 0.27586206896551724]\n",
    "p = [0.03571428571428571, 0.1875, 0.3055555555555556, 0.4]\n",
    "print(f1(r,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(root, validation_set, start):\n",
    "    \n",
    "    #print(type(root))\n",
    "    #print('Left Room', root['left']['room'])\n",
    "    #print('Right Room', root['right']['room'])\n",
    "\n",
    "    \n",
    "    \n",
    "    if ((root['left']['emitter'] == -1) and (root['right']['emitter'] == -1)):\n",
    "        \n",
    "        old = [root['emitter'], root['value'], root['room'], root['right'], root['left']]\n",
    "\n",
    "        cm, old_accuracy = evaluate(validation_set, start)\n",
    "        \n",
    "        #print('NumLeft: ', numClasses[root['left']['room']])\n",
    "        \n",
    "        if(root['left']['count'] > root['right']['count']):\n",
    "            root['room'] = root['left']['room']\n",
    "        else:\n",
    "            root['room'] = root['right']['room']\n",
    "\n",
    "        root['left'] = -1\n",
    "        root['right'] = -1\n",
    "        root['emitter'] = -1\n",
    "        root['value'] = -1\n",
    "        \n",
    "        cm, new_accuracy = evaluate(validation_set, start)\n",
    "        \n",
    "        if new_accuracy < old_accuracy:\n",
    "            root['emitter'] = old[0]\n",
    "            root['value'] = old[1]\n",
    "            root['room'] = old[2]\n",
    "            root['right'] = old[3]\n",
    "            root['left'] = old[4]\n",
    "        \n",
    "               \n",
    "    else:\n",
    "        \n",
    "        if(root['left']['emitter'] != -1):\n",
    "            start = prune(root['left'], validation_set, start)\n",
    "        if(root['right']['emitter'] != -1):\n",
    "            start = prune(root['right'], validation_set, start)\n",
    "    \n",
    "    return start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_prune(dataset):\n",
    "\n",
    "#shuffle \n",
    "    np.random.shuffle(dataset)\n",
    "#take a set\n",
    "\n",
    "    fold_size = int(len(dataset)/10)\n",
    "    classes = set({})\n",
    "    running_cm = np.zeros((4,4))\n",
    "    running_cm_pr = np.zeros((4,4))\n",
    "    \n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        classes.add(dataset[i][-1])\n",
    "    \n",
    "    for i in range(10):\n",
    "        \n",
    "        #numclasses = {1:0, 2:0, 3:0, 4:0}\n",
    "        test = dataset[fold_size*i:fold_size*(i+1)]\n",
    "        validation = dataset[fold_size*(i+1)+1:fold_size*(i+2)+1]\n",
    "        training = np.vstack((dataset[0:fold_size*i],dataset[fold_size*(i+2)+1:]))\n",
    "        root, depth = tree_learning(training, 0)\n",
    "        \n",
    "        \n",
    "        confusion_matrix, tree_accuracy = evaluate(test, root)        \n",
    "        running_cm += confusion_matrix\n",
    "        \n",
    "        #========================================================================================#\n",
    "        \n",
    "#         for j in training:\n",
    "#             numclasses[j[-1]]+=1\n",
    "        \n",
    "        #print(numclasses)\n",
    "        pruned_tree = prune(root, validation, root)\n",
    "#         print('Depth after:', findDepth(pruned_tree))\n",
    "        \n",
    "        cm_prune, pr_acc = evaluate(test, pruned_tree)\n",
    "        running_cm_pr += cm_prune\n",
    "        \n",
    "#         print(depth, \" vs \", findDepth(pruned_tree))\n",
    "#         print(tree_accuracy, \" vs \", pr_acc)\n",
    "\n",
    "        #========================================================================================#\n",
    "    \n",
    "    avg_cm = running_cm/10\n",
    "    avg_cm_pr = running_cm_pr/10\n",
    "    \n",
    "#     print(\"Before prune accuracy:\", accuracy(avg_cm))\n",
    "#     print(\"After prune accuracy:\", accuracy(avg_cm_pr))\n",
    "    \n",
    "    return accuracy(avg_cm)\n",
    "    \n",
    "    \n",
    "        \n",
    "#cycle validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8044999999999999\n",
      "Runtime:  108.35124897956848\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------#\n",
    "testing = np.loadtxt(\"noisy_dataset.txt\")\n",
    "st=time.time()\n",
    "print(cross_validation_prune(testing))\n",
    "et=time.time()\n",
    "print('Runtime: ', et-st)\n",
    "#-----------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findDepth(node): \n",
    "    \n",
    "    lDepth = 0\n",
    "    rDepth = 0\n",
    "    \n",
    "    if node is None: \n",
    "        return 0 ;  \n",
    "  \n",
    "    else : \n",
    "  \n",
    "        # Compute the depth of each subtree \n",
    "        \n",
    "        if(node['left']['emitter'] != -1):\n",
    "            lDepth = findDepth(node['left']) \n",
    "        if(node['right']['emitter'] != -1):\n",
    "            rDepth = findDepth(node['right']) \n",
    "  \n",
    "        # Use the larger one \n",
    "        if (lDepth > rDepth): \n",
    "            return lDepth+1\n",
    "        else: \n",
    "            return rDepth+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
